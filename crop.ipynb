{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from voc_eval import parse_rec as readxml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "counter={\"waldo\":0, \"wenda\":0, \"wizard\":0}\n",
    "\n",
    "# check same number of annocations and images\n",
    "#if len(os.listdir(\"datasets/Annotations/\")) != len(os.listdir(\"datasets/JPEGImages\")):\n",
    "    #raise Exception(\"there are not similar numbers of annotations and images\")\n",
    "\n",
    "# Images IDs to run on\n",
    "# image_ids_file = open(\"datasets/ImageSets/val.txt\", 'r')\n",
    "image_ids_file = open(\"datasets/ImageSets/train.txt\", 'r')\n",
    "image_ids = image_ids_file.readlines()\n",
    "\n",
    "for image_id in image_ids:\n",
    "    image_id = image_id.strip('\\n')\n",
    "# for ind1 in range (len(os.listdir(\"datasets/Annotations/\"))):\n",
    "    number = str(image_id)\n",
    "    while len(number) < 3:\n",
    "        number = \"0\" + number\n",
    "    \n",
    "    annotation_file = \"datasets/Annotations/\"+number+\".xml\"\n",
    "    image_file = \"datasets/JPEGImages/\"+number+\".jpg\"\n",
    "    \n",
    "    #sanity check if files are present\n",
    "    if not osp.isfile(annotation_file):\n",
    "        continue\n",
    "        \n",
    "    if not osp.isfile(image_file):\n",
    "        continue\n",
    "        \n",
    "    boxes = readxml(annotation_file)\n",
    "    image = np.asarray(cv2.imread(image_file))\n",
    "    #box is a list of dictionaries\n",
    "    \n",
    "    #print(\"boxes\")\n",
    "    #print(boxes)\n",
    "    #print(\"len(boxes)\")    \n",
    "    #print(len(boxes))\n",
    "    \n",
    "    for img_ind in range (len(boxes)):\n",
    "        box = boxes[img_ind]\n",
    "        name = box[\"name\"]\n",
    "        bbox = box[\"bbox\"]\n",
    "        \n",
    "        #sanity check\n",
    "        \n",
    "        #print(\"image.shape\")\n",
    "        #print(image.shape)      \n",
    "        #print(\"name\")\n",
    "        #print(name)\n",
    "        #print(\"bbox\")\n",
    "        #print(bbox)\n",
    "        \n",
    "        #bbox is in [x1,y1,x2,y2]\n",
    "        crop_image = image[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        crop_number = str(counter[name])\n",
    "        counter[name] = counter[name] + 1\n",
    "        if len(crop_number) < 4:\n",
    "            crop_number = \"0\" + crop_number\n",
    "        crop_name = name + \"_\" + str(image_id) + \"_\" + crop_number + \".jpg\"\n",
    "        crop_path = \"datasets/crop_train/\" + crop_name\n",
    "        cv2.imwrite(crop_path, crop_image)\n",
    "        #plt.imshow(imread(crop_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
